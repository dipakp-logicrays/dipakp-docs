# This robots.txt file controls crawling of URLs under https://dipakp-docs.readthedocs.io.

User-agent: *

Disallow: # Allow everything

Sitemap: https://dipakp-docs.readthedocs.io/sitemap.xml
Sitemap: https://dipakp-docs.readthedocs.io/site-sitemap.xml

